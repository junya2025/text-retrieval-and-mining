{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial I - Text Processing and Information Retrieval"
      ],
      "metadata": {
        "id": "fLiLdCMlPeu9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Duration:** 1.5 hour\n",
        "\n",
        "**Prerequisites:** Basic Python knowledge, familiarity with pandas and numpy\n",
        "\n",
        "**Learning Objectives**\n",
        "*   Understand basic text preprocessing techniques\n",
        "*   Implement text cleaning and normalization\n",
        "*   Calculate TF-IDF scores\n",
        "*   Create a simple document search system\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gq_TLZUaOw6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "6JQLYRwwPyzB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ei_X9mI8Ostb"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1: Text Cleaning (20 minutes)\n",
        "Implement a function that cleans text by:\n",
        "\n",
        "\n",
        "*   Converting to lowercase\n",
        "*   Removing special characters\n",
        "*   Removing extra whitespace\n",
        "*   Removing HTML tags (hint: look for content between < and >)"
      ],
      "metadata": {
        "id": "HLZOOmQBP8RG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Clean and normalize text data.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text to clean\n",
        "\n",
        "    Returns:\n",
        "        str: Cleaned text\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    pass\n",
        "\n",
        "# Test your function\n",
        "test_text = \"\"\"<p>This is a    Sample Text\n",
        "with HTML tags</p> & special chars!!!\"\"\"\n",
        "print(\"Original:\", test_text)\n",
        "print(\"Cleaned:\", clean_text(test_text))"
      ],
      "metadata": {
        "id": "nw4tpqblOx3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2: Building a TF-IDF Search Engine  (30 minutes)\n",
        "Create a simple search engine using TF-IDF to find relevant documents."
      ],
      "metadata": {
        "id": "v5ShpLFVQUv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleSearchEngine:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the search engine with TF-IDF vectorizer\"\"\"\n",
        "        # Your code here\n",
        "        pass\n",
        "\n",
        "    def add_documents(self, documents):\n",
        "        \"\"\"\n",
        "        Add documents to the search engine\n",
        "\n",
        "        Args:\n",
        "            documents (list): List of text documents\n",
        "        \"\"\"\n",
        "        # Your code here\n",
        "        pass\n",
        "\n",
        "    def search(self, query, top_k=2):\n",
        "        \"\"\"\n",
        "        Search for documents most relevant to query\n",
        "\n",
        "        Args:\n",
        "            query (str): Search query\n",
        "            top_k (int): Number of results to return\n",
        "\n",
        "        Returns:\n",
        "            list: Indices of top_k most relevant documents\n",
        "        \"\"\"\n",
        "        # Your code here\n",
        "        pass\n",
        "\n",
        "# Test documents\n",
        "documents = [\n",
        "    \"The cat and the dog play\",\n",
        "    \"The dog chases a ball\",\n",
        "    \"A cat naps in the sun\",\n",
        "]\n",
        "\n",
        "# Create and test your search engine\n",
        "search_engine = SimpleSearchEngine()\n",
        "search_engine.add_documents(documents)\n",
        "results = search_engine.search(\"cat playing\")\n",
        "print(\"Search Results:\", results)"
      ],
      "metadata": {
        "id": "ofx6tdRVQQcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3: Document Similarity (20 minutes)\n",
        "Implement a function to find similar documents using cosine similarity."
      ],
      "metadata": {
        "id": "SHvCYlIURbMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_similarity(doc1, doc2):\n",
        "    \"\"\"\n",
        "    Calculate cosine similarity between two documents\n",
        "\n",
        "    Args:\n",
        "        doc1 (str): First document\n",
        "        doc2 (str): Second document\n",
        "\n",
        "    Returns:\n",
        "        float: Similarity score between 0 and 1\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    pass\n",
        "\n",
        "# Test documents\n",
        "doc1 = \"The quick brown fox jumps over the lazy dog\"\n",
        "doc2 = \"The fast brown fox leaps over the sleepy dog\"\n",
        "doc3 = \"Python programming is fun and interesting\"\n",
        "\n",
        "print(\"Similarity score (similar docs):\", calculate_similarity(doc1, doc2))\n",
        "print(\"Similarity score (different docs):\", calculate_similarity(doc1, doc3))"
      ],
      "metadata": {
        "id": "Mpy9GOOYRDiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 4: Putting It All Together (20 minutes)\n",
        "Use everything you've learned to create a complete document processing pipeline."
      ],
      "metadata": {
        "id": "Ska2wStqRqWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_documents(documents):\n",
        "    \"\"\"\n",
        "    Process a collection of documents:\n",
        "    1. Clean each document\n",
        "    2. Calculate TF-IDF\n",
        "    3. Find most similar document pairs\n",
        "\n",
        "    Args:\n",
        "        documents (list): List of text documents\n",
        "\n",
        "    Returns:\n",
        "        tuple: (processed_docs, similarity_matrix)\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    pass\n",
        "\n",
        "# Test the complete pipeline\n",
        "test_docs = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"<p>A quick brown fox leaps over a lazy dog!</p>\",\n",
        "    \"Programming in Python: A beginner's guide to coding\",\n",
        "    \"Python programming tutorial for beginners\"\n",
        "]\n",
        "\n",
        "processed_docs, similarity_matrix = process_documents(test_docs)\n",
        "print(\"Processed Documents:\", processed_docs)\n",
        "print(\"\\nSimilarity Matrix:\\n\", similarity_matrix)"
      ],
      "metadata": {
        "id": "4YdI10woRiO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YX_ZWYvrSFlC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}